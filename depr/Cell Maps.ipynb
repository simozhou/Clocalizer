{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/anaconda3/envs/bioch_project/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we really want to do is building a *custom estimator* which will simplify our life for results tracking and data visualization. Further improvements might include a distributed Cloud version of it to overcome the important computational cost it requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading datasets and phreshing folds for evaluations and testing\n",
    "train_ds, test_ds = np.load(\"train.npz\"), np.load(\"test.npz\")\n",
    "\n",
    "partition, x_train, y_train = train_ds[\"partition\"], train_ds[\"X_train\"], train_ds[\"y_train\"]\n",
    "x_test, y_test = test_ds['X_test'], test_ds['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First attempt, _without_ cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the actual training phase:\n",
    "\n",
    "for cross validation, we train the data on 4 different models by splitting the dataset in 4 subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './checkpoints_tutorial17-1/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9ec979c4a8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(\"X\", shape=(1000, 20))]\n",
    "\n",
    "num_hidden_units = [512, 256, 128]\n",
    "    \n",
    "model = tf.estimator.DDN(feature_columns=feature_columns,\n",
    "                                       n_classes=10,\n",
    "                                       model_dir=\"./checkpoints_tutorial17-1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3d3dca26a541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                                                    shuffle=False)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# giving an error, but at least we've fixed it\n",
    "for i in range(1,5):\n",
    "    x_part, y_part, x_val, y_val = x_train[np.where(partition != i)], y_train[np.where(partition != i)], x_train[np.where(partition == i)], y_train[np.where(partition == i)] \n",
    "    \n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(x={'X':x_part},\n",
    "                                                   y=y_part,\n",
    "                                                   num_epochs=1,\n",
    "                                                   batch_size=128,\n",
    "                                                   shuffle=False)\n",
    "    \n",
    "    model.train(input_fn=train_input_fn, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_input_fn = tf.estimator.inputs.numpy_input_fn(x={'X':x_test},\n",
    "                                                   y=y_test,\n",
    "                                                   num_epochs=20,\n",
    "                                                         batch_size=128,\n",
    "                                                   shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model function\n",
    "def cnn_clocator(inputs, classes, mode):\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(inputs=inputs, filters=50, kernel_size=3,\n",
    "                             padding=\"same\", activation=tf.nn.relu)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(inputs=conv1, filters=80, kernel_size=5,\n",
    "                             padding=\"same\", activation=tf.nn.relu)\n",
    "    \n",
    "    pool = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    pool_flat = tf.layers.flatten(pool)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1194"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[np.where(partition == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(x={'X':x_train[np.where(partition == 1)]},\n",
    "                                                   y=y_train[np.where(partition == 1)],\n",
    "                                                   num_epochs=1,\n",
    "                                                   shuffle=False)\n",
    "    \n",
    "model.train(input_fn=train_input_fn, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
